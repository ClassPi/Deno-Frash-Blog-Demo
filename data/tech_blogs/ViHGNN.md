---
title: Vision HGNN
type: tech
---
<head>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous"/>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "\\[", right: "\\]", display: true},
                {left: "$", right: "$", display: false},
                {left: "\\(", right: "\\)", display: false},
                {left: "{", right: "}", display: false},
                {left: "\{", right: "\}", display: false}
            ]
        });
    });
    </script>
    <style>
    *{
        font-family: 'Arial Rounded MT', 'SimHei', sans-serif;
    }
    .katex{
        background-color: #f0f0f0;
        font-size: .95rem;
        margin-left: .1rem;
        margin-right: .1rem;
    }
    small{
        letter-spacing: .1rem;
        color: gray;
    }
    a:link{
        color: #06e348;
        font-weight: bold;
    }
    a:link: hover{
        color: #28bd28
    }
    strong{
        font-weight: bold;
    }
    </style>

</head>

<section>

# **Vision HGNN**

## **摘要**

图基模型的领域已经证明了其在多种现实世界数据类型中的适应性. 然而, 其在一般计算机视觉任务中的应用性一直受限, 直到引入视觉图神经网络(ViG). ViG将输入图像分割为块, 将这些块概念化为节点, 通过连接到最近邻居来构建图. 尽管如此, 这种图构建方法将自身限制于简单的成对关系, 导致边缘过剩和不必要的内存与计算成本. 在这篇论文中, 我们通过超越传统的"成对"连接并利用超图的力量来增强ViG, 以封装图像信息. 我们的目标是包含更多细节的块间关系. 在训练和推理阶段, 我们巧妙地建立并更新超图结构, 使用模糊C均值方法, 确保最小的计算负担. 这种增强产生了视觉超图神经网络(ViHGNN). 模型的有效性通过其在图像分类和目标检测任务上的最新表现得到了实证验证, 揭示了层次更高的关系学习模块. 我们的代码可在以下地址获得: <https://github.com/VITA-Group/ViHGNN>

</br>

---

</br>

## **1. 领域介绍**

深度学习领域的迅速进步带来了多种计算机视觉模型的显著成功. 这些包括卷积神经网络(CNNs), 视觉变换器(ViTs), 以及基于多层感知器(MLP)的视觉模型. 在这些网络中, 输入图像要么以欧几里得空间中的规则像素网格形式表示, 要么以补丁序列的形式表示.

> 补丁序列通常指的是将输入图像分割成一系列较小的图像块或"补丁", 然后将这些补丁 按照某种顺序排列成序列.

尽管如此, 通过图结构进行更多样化的图像处理的潜力仍未被发掘. 最近的发展, ViG[**<span class='tag'>18</span>**], 巧妙地利用了图神经网络(GNNs)在大规模视觉任务中取得了实质性的进步. 为了减少节点过多的问题, ViG借鉴了ViT的划分概念, 将图像分割成更小的块, 并指定每个块为一个节点. 因此, ViG框架在节点及其最近邻之间建立连接, 构建了一个可适应的图. 进一步, 图本身作为一个泛化的数据结构出现, 包含网格和序列作为其更广泛图上下文中的不同实例.
虽然视觉图神经网络(ViG)的成功有效地展示了将图像作为图处理在增强灵活性和视觉感知有效性方面的优势, 但使用图作为图像表示的最佳数据结构存在局限性. 这些局限性根植于两个主要原因:

1. **关系的复杂性**: 一个简单图的基本限制在于它的能力仅限于连接两个节点, 因此它只能适应成对的关系. 这种不足在模拟高阶关系时尤为明显, 而这在图像中是固有的. 考虑计算机视觉中的对象识别任务, 图像通常被分割成多个补丁, 每个补丁代表物体的一部分. 这种分割引入了复杂的补丁之间的内部和外部依赖关系, 而一个简单直观的图结构难以捕捉这种复杂性. 这种复杂性源于同一或不同物体的补丁之间的相互作用. 因此, 一个传统的图结构发现很难有效地模拟补丁之间这种多方面的关系.
2. **边的冗余生成**: 另一个与简单图表示法相关的问题是在图像描述过程中生成冗余的边. ViG通过识别每个补丁节点的最近邻居来构建其图形, 并随后形成节点对之间的边. 在这个过程中, 所有图像补丁都被转换为特征向量, 并计算特征距离以确定最近邻居. 当考虑到图像中的一个对象通常是多个补丁的混合体时, 这种方法就会变得有问题, 因为属于同一对象的补丁产生相似的特征向量. 因此, 图形构建方法可能无意中产生额外的冗余边. 在最坏的情况下, 一个包含n个补丁的图像可能会生成n²个边, 导致四次方的复杂度.

<p id='pic1'></p>

![加载失败? 请确认可以访问Github!](https://raw.githubusercontent.com/ClassPi/PicBed/master/images20240112141203.png)
<small>图1. 不同视觉骨干网络中建模的图像拓扑结构示意图. (a)CNN将图像视为规则的网格, (b)ViT将图像解析为全连接图, (c)ViG处理图像为带有成对边的稀疏图, (d)我们的ViHGNN将图像模型化为超图, 一种"更通用"的结构. </small>

前述的考虑凸显了依赖简单图形作为图像表示的基本数据结构所固有的局限性. 因此, 探索能够有效解决这些问题的替代方法学是必要的, 从而增强视觉感知模型的精细度. 有鉴于此, 我们提出了ViG的一个强大演化版本, 在这个版本中, 超图扮演图像表示的角色. 这一创新框架, 名为Vision HGNN(ViHGNN), 引入了一种动态方法来改进图像表示. 具体来说, 超图作为一个图的广义扩展, 由一系列节点和超边组成. 与简单图中的成对连接不同, 超图内的超边可以连接任意数量的节点. 本质上, 一个图可以被视为超图的一种专门形式, 只考虑成对连接之间的数据点. 有别于此, 超图在捕捉图像内部存在的错综复杂的关联性方面表现出更优的能力, 超越了成对关系的限制. 要查看具体例子, 请参见 <a href='#pic1'>图1</a>

然而, 一个基本的挑战仍然存在：确定图像表示的最优超图结构. 这涵盖了一个"先有鸡还是先有蛋"的问题: 一方面有利用超图进行图像表示的愿望, 另一方面却缺乏一个现成可用的超图结构. 受到ViG的图构建方法的启发, 我们从利用补丁特征来构建初始超图开始. 随后, 初始超图生成补丁嵌入, 然后这些嵌入被用于构建一个更新的超图结构. 至关重要的是, 补丁嵌入和超图结构经历动态更新, 最终形成一个自我强化的学习过程的"反馈循环". 在ViHGNN框架中, 我们选择**模糊C均值方法**(见第3.3节)来构建和更新超图结构, 从而产生的计算开销可以忽略不计. 我们的贡献可以总结如下：

1. 我们在ViG框架的基础上进一步发展, 提出了一个名为ViHGNN的新范式, 它将图像解释为一个动态的超图. 与ViG不同, ViHGNN不仅捕获图像内的高阶关系, 还减少了与图结构相关的冗余内存和计算开销.
2. 为了建立一个稳健的图像超图表示, 我们在框架内无缝集成了一个自适应超图结构学习模块, 从而增强了表示, 同时几乎不增加开销. 这种图像的超图描述为下游视觉任务提供了明显的优势.
3. 我们执行全面的实验来强调ViHGNN模型在视觉任务中的有效性, 包括图像分类和对象检测. 具体来说, 我们的ViHGNN模型在ImageNet分类任务中实现了83.9%的顶级准确率, 以及在COCO对象检测任务中实现了令人印象深刻的43.1%的平均精确度(AP).

> 一些不太精确的数据: ResNet-50：顶级准确率(Top-1 Accuracy)大约为76.5%, Inception-v3：顶级准确率大约为 78.8%, VGG-16：顶级准确率大约为71.5%, EfficientNet-B7：顶级准确率大约为84.4%. FasterR-CNN：平均精确度(AP)大约为 37.4%, YOLOv3：平均精确度大约为33.0%, SSD300：平均精确度大约为 41.2%, EfficientDet-D7：平均精确度大约为51.5%

---
<div style="page-break-after: always;"></div>

## **2.相关工作**

**在计算机视觉中的网络架构**. 卷积神经网络[CNNs](35, 33, 22) 曾被视为计算机视觉中的事实上的标准, 用于图像分类[35, 33], 对象检测[47], 语义分割[43]等多个方面. 随着过去十年中快速的发展, 基于残差网络的CNNs包括ResNet[22], MobileNet[25]和NAS搜寻的网络[73, 84]越来越受欢迎. 最近, 受到NLP领域Transformer架构成功的启发, 为视觉任务引入了视觉Transformer[17, 11, 3, 4]. ViT[11]的开创性工作直接将Transformer架构应用到非重叠的中等大小的图像块上进行图像分类. 自那以后, ViT的许多变种已经被提出以提高视觉任务的性能. 主要改进包括金字塔架构[67, 41], 局部注意力[19, 41]以及位置编码[62]. 此外, MLP架构也在计算机视觉中被探索[54, 55, 3, 57, 15, 53], 同样, 大核心CNNs也被探索[42, 9, 40, 28].

**在计算机视觉中的图/超图**. 尽管图神经网络(GNNs)传统上是被应用在在社交网络[16]、引文网络[49]和生物化学图[59]中, 但它们的应用已经扩展到计算机视觉领域. 值得注意的是, GNNs已经被探索用于点云分类和分割[34, 63], 以及结合对象检测器和GNNs[69, 72]的场景图生成. 此外, GNNs通过关节连接图[31, 71]在人类行为识别中被证明可行.

超图神经网络(HGNNs)是一种相关的范式, 因为超图包括了图[64, 20]. 在计算机视觉中, HGNNs具有广泛的用途. 例如, 在图像检索中, 顶点代表图像, 超边基于特征相关性生成[30]. 同样地, 三维物体分类采用物体的顶点表示, 并使用视角关系来创建超边[29, 14]. 个体重识别利用特征相关性来构建超图[80]. 然而, 尽管GNNs和HGNNs在各个领域都很突出, ViG是少数直接处理图像数据的方法之一[18].


**图/超图结构学习**. GNN和HGN对于分析图和超图结构至关重要. 这些方法使得对于给定的图和超图结构的分析相互交织在一起. 近期的努力已经集中在图/超图结构和学习上. 对于GNN, 像[6, 13]这样的方法联合学习图结构和图节点嵌入, 基于图邻接矩阵某些假设, 如低秩、稀疏性或平滑性. 其他方法, 如[45, 81]学习概率分布以决定是否修改图结构. 相比之下, 在结构学习中, DHSL[79, 78]的结构优化问题较少被探索. DHSL同时学习标签投影矩阵和超图结构. DHGNN[32]采用K-Means和k-NN来自适应地构建超图. HERALD[77]通过优化超图拉普拉斯矩阵来优化超图结构. 这些方法优化超图结构, 但面临如非凸性和高计算成本等挑战. 传统非凸优化方法在动态超图结构中导致收敛问题, 高时间复杂度, 特别是在DHSL[79, 78]中, 在迭代优化过程中, 对时间效率的超图更新表示担忧.

---
<div style="page-break-after: always;"></div>

## **3. 方法: 一图--超图**
<a id='pic2'></a>

![加载失败? 请确认可以访问Github!](https://raw.githubusercontent.com/ClassPi/PicBed/master/images/20240112162456.png)
<small>图2. 我们的ViHGNN模型概述. HGNN和FNN分别代表超图神经网络和前馈网络. </small>

在本节中, 我们首先介绍全文中使用的符号和定义. 然后我们提出了超图神经网络(ViHGN)框架。整个概述在 <a href='#pic2'>图2</a> 中展示

### **3.1 符号和定义**

**符号**. 设 $I∈R^{H×W×3}$  表示一个大小为 $H×W$ 的图像，我们将每个图像均匀划分为 $N$ 个块. 将每个块转换为特征向量 $x_i∈R^D$ 后, 我们得到一个数据矩阵 $X =[x_1, x_2, ..., x_n]$, 其中每列对应于一个块的特征向量，$i = 1, 2, ..., N$，$D$ 是特征维度.

**超图定义**. 超图被定义为 $G=(V,E)$, 其中 $V$ 是 $N$ 个唯一顶点的集合, $E$ 是 $E$ 个超边的集合. 不同于普通图, 每个超边 $e∈E$ 可以连接多于两个顶点. 超图可以通过一个邻接矩阵 $H∈\{0,1\}^{N×E}$ 来表示, 其中如果超边 $e∈E$ 包含顶点 $v_i∈V$, 则 $H_{ie} = 1$; 否则 $H_{ie} = 0$. 对于每个顶点和超边, 我们定义了度 $D_{ii} = ∑_{e=1}^E H_{ie}$ 和 $B_{ee} = ∑_{i=1}^N H_{ie}$, 将这些对角线元素构建成$D$和$B$两个度矩阵, $D_{ii}$ 和 $B_{ee}$ 分别是 $D$ 和 $B$ 的第 $i$ 和第 $e$ 个对角线元素. 对于一个图像, 我们将图像块视为一组无序的节点,并定义节点集合$V=\\{\{v_1,v_2,...,v_n\}\\}$. 我么将图像$I$转换为超图$G(I)$来表示图像的超图结构. 超图构建过程将在第3.3节详细介绍.🥳

<a id='pic3'></a>

![加载失败? 请确认可以访问Github!](https://raw.githubusercontent.com/ClassPi/PicBed/master/images/20240115093820.png)
<small><p style="text-align:center">图3.(a)HGNN和(b)GNN中消息传递机制的比较</p></small>

**超图神经网络**. 一个通用的超图卷积层被定义为<a id='math1'>[公式1]</a>:
$$ x^{(l+1)} = D^{-1/2} H \sigma(W B^{-1} H^{T} \sigma (D^{-1/2} x^{(l)} \Theta_1)\Theta_2)\qquad(1)$$ 

$W$是超边权重矩阵, $\Theta_1$ 和 $\Theta_2$ 是可学习的HGN层的参数, $\sigma$是激活函数, $X^{l}$和$X^{l+1}$分别代表输入和输出的节点嵌入. 超图卷积可以看作是以"节点-超边-节点"方式传递信息的两阶段消息. $H^T$的乘法实现了从节点到超编的信息聚合. 乘以$H$可以看作是从超边到节点的信息聚合. 在两者之间, D和B进行归一化. 
普通GNN和HGNN之间消息传递的差异如<a href='#pic3'>图3</a>所示. 乍一看等式 (1)只是在超图的组展开上运行一个简单的GNN. 然而, HGNN中的消息将在节点端和超边缘端被接收和转换, 这不能通过clique expansion来实现[7]

>"clique expansion" 是指将超图转换为普通图的过程，以便可以在其上运行普通的图神经网络(GNN)

### **3.2 概述: ViHGNN 框架**

在一次迭代中, 输入图像I首先被分成$N$个斑块, 这些斑块被转换为一组特征向量, 如<a href='#pic2'>图2</a>中的斑块嵌入所示. 然后通过Fuzzy C-Means[1]对这些补丁进行聚类, 以构建超图$G(I)$.

>Fuzzy C-Means(FCM)是一种聚类算法, 它是K-Means聚类算法的一种扩展. 在K-Means算法中, 一个数据点只能属于一个特定的集群, 而在Fuzzy C-Means算法中, 一个数据点可以属于多个集群, 并且每个集群都有一个特定的隶属度. 😅

然后, 超图卷积层可以通过两阶段节点-超边-节点消息传递方案在节点之间交换信息.我们在超图卷积层之后应用前馈网络(FFN), 将节点特征投射到同一域中, 增加特征多样性.并且FFN层进一步提高了特征变换能力, 缓解了过度平滑现象[10,61,50]. 

>什么是过渡平滑现象? 这个问题发生在多层GNN中, 当我们进行多轮的信息传递(即节点之间的信息交换)时, 节点的特征开始收敛, 变得越来越相似. 这就是所谓的过度平滑现象. 

输出更新的补丁嵌入依次输入Fuzzy C-Means, 以更新超图G(I). 第3.4节详细说明了这一提议的来回流程背后的基本原理. ViHGNN通过逐步更新超图和评估超图结构化特征表示来迭代上述任务. 我们在末尾附加一个池化和MLP模块, 以在之后Regress to output logits. 我们提供ViHGNN的各种架构配置, 如表2所示.

>"Regress to output logits" 是指使用回归模型来预测输出的logits. 在机器学习中, logits 通常是指一个模型的输出层(通常是未经激活函数处理的)的原始预测值



### **3.3 图像的超图结构**

接下来, 我们将解释如何为图像I构造超图G(I), 在前文中提到, 图像的均匀切割块可以被看作是一组无序节点$V=\lbrace v_1,v_2,...,v_n \rbrace$, 将每个块转换为特征向量后, 我们得到一个特征矩阵 $X =[x_1, x_2, ..., x_n]$. 从ViG的图构造方法中汲取灵感, 我们构造了一个超图来推断补丁拓扑. 与 ViG 基于距离的策略类似, 我们利用节点特征距离进行超图构建, 但是我们与之有违的是使用了Fuzzy C-Means方法来生成节点集群. 这些重叠的簇表示图像面块集, 类似于超边. 此配置将超图转换为不同节点集群的集合. 重要的是, 与 K-Means 相比, Fuzzy C-Means 允许聚类具有非空交集. 因此, 节点可能以多个超边的形式出现, 从而促进图像块之间复杂多样的对象间关系. 重申graph representation of the image 的优点: 
1. 超图是一种广义的数据结构, 其中网格, 序列甚至图都可以看作是超图的特例;
2. 超图比图更灵活, 可以对图像中复杂的高阶关系进行建模;
3. HGNN的先进研究可用于视觉任务的有效图表示. 

### **3.4 自适应超图结构学习**

超图结构虽然在模拟图像斑块之间的复杂相关性方面非常强大, 但它依赖于由同一超边连接的节点具有相似表示的假设. 然而, 构建这种结构是具有挑战性的, 因为它取决于有意义和强大的图补丁嵌入, 而这些嵌入在学习过程之前是不可用的. 此外, 超图中的噪声信息可能会集成到学习到的节点表示中, 从而可能降低ViHGNN模型的性能. 这可能导致不同对象之间共享超边, 从而降低图像辨别力并损害分类和对象检测任务. 
为了解决这个问题, 优化超图结构, 消除或减少与任务无关的联系, 同时增强有影响力的联系至关重要. 优化的最终目标是在图补丁中实现高阶相关性的准确和完整表示. 然而, 这带来了一个"先有鸡还是先有蛋"的问题: 生成一个健壮的超图依赖于补丁嵌入,而有意义的补丁嵌入依赖于超图结构?? 为了克服这个问题, 我们建立了一个"反馈循环" 其中patch嵌入和超图相辅相成,动态更新在两者之间交替进行, 从而增强了结构感知图像表示.引入固定数量的超边作为正则化器, 进一步防止了超图中的琐碎结构,提高了其有效性,这种迭代过程确保了补丁嵌入和超图结构的相互改进,尽管它们是相互依赖的.

![](https://raw.githubusercontent.com/ClassPi/PicBed/master/images/20240116095531.png)
![](https://raw.githubusercontent.com/ClassPi/PicBed/master/images/20240116095555.png)
<small>D:特征维度, h:FFN中的隐藏维度比, E:HGNN中的超边数,H×W: 输入图像大小. "Ti"表示tiny, "S"表示small，"M"表示medium, "B"表示base</small>

### 3.5 **端到端优化**

在ViHGNN中, 自适应超图结构更新依赖于学习的补丁嵌入. 在每个ViHGNN 模块的训练和推理过程中, 这些嵌入塑造了超图结构. 在推理中, 固定的模型权重导致稳定的超图结构. 此过程独立于梯度计算运行, 不会影响反向传播.

....(关于实验的部分请浏览原文)
<section>
